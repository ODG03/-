import pyaudio
import wave
import whisper
import google.generativeai as genai
import difflib
from difflib import SequenceMatcher
from rapidfuzz import fuzz
import time
import re
import pandas as pd
import numpy as np


API_KEY = "AIzaSyDRaStCE57-Z67lzx6mNFpYNlDDyuwP9J4"
genai.configure(api_key=API_KEY)
choice = input("è‡ªåˆ†ã®æ–‡ç« ã‚’ä½¿ã„ã¾ã™ã‹ï¼Ÿ [Yes or No] :")
foreign_lang = input("ä½•èªã‚’ãƒã‚§ãƒƒã‚¯ã—ã¾ã™ã‹ï¼Ÿ [éŸ“å›½èª or è‹±èª] :")
def get_foreign_example(foreign_lang):
    model_ai = genai.GenerativeModel("gemini-2.0-flash")
    response = model_ai.generate_content(f"{foreign_lang}ã®ç°¡å˜ãªæ–‡ã‚’ã„ãã¤ã‹ç”Ÿæˆã—ã¦ãã ã•ã„.æ—¥æœ¬èªã®èª¬æ˜ã¯ä¸è¦ã§ã™ã€‚{foreign_lang}ã®æ–‡ç« ã®ã¿ã‚’å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚")
    return response.text

if choice=="Yes":
    raw_text = input("\næ–‡ç« ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„:")

else:
    # AIã‹ã‚‰éŸ“å›½èªã®ä¾‹æ–‡ã‚’å–å¾—
    raw_text = get_foreign_example(foreign_lang)


# æ–‡å˜ä½ã§åˆ†å‰²ï¼ˆã€Œ.ã€ã€Œ?ã€ã€Œ!ã€ã§åŒºåˆ‡ã‚‹ï¼‰
foreign_sentences = [sentence.strip() for sentence in re.split(r'\s*[.?!]\s*', raw_text) if sentence.strip()]
model_listen = whisper.load_model("medium")

# éŒ²éŸ³ã®è¨­å®š
FORMAT = pyaudio.paInt16
CHANNELS = 1
RATE = 44100
CHUNK = 1024
RECORD_SECONDS = 8  # å„æ–‡ã®éŒ²éŸ³æ™‚é–“
OUTPUT_FILENAME = "output.wav"

#çµæœã®è¡¨ç¤º
results = []

# å„æ–‡ã”ã¨ã«éŸ³èª­ï¼†æ¯”è¼ƒ
for index, sentence in enumerate(foreign_sentences):
    print(f"\nğŸ”Š {index+1}ç•ªç›®ã®æ–‡ã‚’éŸ³èª­ã—ã¦ãã ã•ã„: {sentence}")

    # éŒ²éŸ³é–‹å§‹ã®è¡¨ç¤ºï¼ˆå¼·èª¿ï¼‰
    print("ğŸ¤ éŒ²éŸ³é–‹å§‹...")
    
    # éŒ²éŸ³é–‹å§‹
    audio = pyaudio.PyAudio()
    stream = audio.open(format=FORMAT, channels=CHANNELS, rate=RATE, input=True, frames_per_buffer=CHUNK)

    frames = []
    for _ in range(0, int(RATE / CHUNK * RECORD_SECONDS)):  # æŒ‡å®šæ™‚é–“éŒ²éŸ³
        data = stream.read(CHUNK)
        frames.append(data)

    print("âœ… éŒ²éŸ³çµ‚äº†")
    stream.stop_stream()
    stream.close()
    audio.terminate()

    # éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¿å­˜
    waveFile = wave.open(OUTPUT_FILENAME, 'wb')
    waveFile.setnchannels(CHANNELS)
    waveFile.setsampwidth(audio.get_sample_size(FORMAT))
    waveFile.setframerate(RATE)
    waveFile.writeframes(b''.join(frames))
    waveFile.close()

    if foreign_lang == "éŸ“å›½èª":
        lang = "ko"
    else:
        lang = "en"

    # Whisperã§æ–‡å­—èµ·ã“ã—
    result = model_listen.transcribe(OUTPUT_FILENAME, language=lang)
    user_sentence = result["text"].strip()

    # Whisperã®å‡ºåŠ›ã‚’ç¢ºèª
    print(f"\nã€Whisperã®å‡ºåŠ›ã€‘ {user_sentence}")

    # AIã®æ–‡ã¨æ¯”è¼ƒ
    similarity = fuzz.ratio(sentence, user_sentence)   # é¡ä¼¼åº¦è¨ˆç®—

    results.append({"AIã®æ–‡": sentence, "ã‚ãªãŸã®ç™ºéŸ³": user_sentence, "é¡ä¼¼åº¦ã‚¹ã‚³ã‚¢": similarity})
    
    print(f"\nã€AIã®æ–‡ã€‘ {sentence}")
    print(f"ã€ã‚ãªãŸã®ç™ºéŸ³ã€‘ {user_sentence}")
    print(f"âœ… é¡ä¼¼åº¦ã‚¹ã‚³ã‚¢: {similarity:.2f}")

    # æ¬¡ã®æ–‡ã«é€²ã‚€å‰ã«å°‘ã—å¾…æ©Ÿ
    time.sleep(1)

#ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã«ã—ã¦è¡¨ç¤º
df = pd.DataFrame(results)
df_text = df.to_string()
print("\n ç™ºéŸ³ãƒã‚§ãƒƒã‚¯\n")
print(df)
model_ai = genai.GenerativeModel("gemini-2.0-flash")
res = model_ai.generate_content(f"ä»¥ä¸Šã®ç™ºéŸ³ãƒã‚§ãƒƒã‚¯çµæœã‚’åˆ†æã—ã¦ã€ã©ã“ã®ç™ºéŸ³ãŒå¼±ç‚¹ã‹ã‚’æŒ‡æ‘˜ã—ã¦ãã ã•ã„\n\n{df_text}")

print("\nğŸ“Š ç™ºéŸ³ã®å¼±ç‚¹åˆ†æ\n")
print(res.text)
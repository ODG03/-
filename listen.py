from flask import Flask, render_template, request
import pyaudio
import wave
import whisper
import google.generativeai as genai
import pandas as pd
import time
import re
from rapidfuzz import fuzz
 # éŒ²éŸ³ã®è¨­å®šï¼ˆåˆæœŸå€¤ï¼‰
FORMAT = pyaudio.paInt16
CHANNELS = 1
RATE = 44100
CHUNK = 1024
OUTPUT_FILENAME = "output.wav"
result = []
audio = pyaudio.PyAudio()
model_listen = whisper.load_model("medium")

#å¤–å›½èªé¸æŠã¨éŒ²éŸ³æ™‚é–“ã®å…¥åŠ›ã‹ã‚‰éŒ²éŸ³ã—ã¦é¡ä¼¼åº¦ã‚’è¿”ã™(1å€‹ã®æ–‡ã«ã¤ã„ã¦è©•ä¾¡)
def listen_evaluate(sentence, foreign_lang, record_time):
    # éŒ²éŸ³å‡¦ç†
    audio = pyaudio.PyAudio()
    stream = audio.open(format=FORMAT, channels=CHANNELS, rate=RATE, input=True, frames_per_buffer=CHUNK)
    frames = []

    for _ in range(0, int(RATE / CHUNK * record_time)):
        data = stream.read(CHUNK)
        frames.append(data)

    stream.stop_stream()
    stream.close()
    audio.terminate()

    # éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜
    waveFile = wave.open(OUTPUT_FILENAME, 'wb')
    waveFile.setnchannels(CHANNELS)
    waveFile.setsampwidth(audio.get_sample_size(FORMAT))
    waveFile.setframerate(RATE)
    waveFile.writeframes(b''.join(frames))
    waveFile.close()

    lang = "ko" if foreign_lang == "éŸ“å›½èª" else "en"

    # Whisperã§æ–‡å­—èµ·ã“ã—
    voice = model_listen.transcribe(OUTPUT_FILENAME, language=lang)
    user_sentence = voice["text"].strip()

    # ğŸ”¹ éŒ²éŸ³ãƒ‡ãƒ¼ã‚¿ãŒç©ºãªã‚‰ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¿”ã™
    if not user_sentence:
        return {"AIã®æ–‡": sentence, "ã‚ãªãŸã®ç™ºéŸ³": "éŒ²éŸ³ãŒæ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ", "é¡ä¼¼åº¦ã‚¹ã‚³ã‚¢": 0}

    similarity = fuzz.ratio(sentence, user_sentence)  # é¡ä¼¼åº¦è¨ˆç®—

    return {"AIã®æ–‡": sentence, "ã‚ãªãŸã®ç™ºéŸ³": user_sentence, "é¡ä¼¼åº¦ã‚¹ã‚³ã‚¢": similarity}
